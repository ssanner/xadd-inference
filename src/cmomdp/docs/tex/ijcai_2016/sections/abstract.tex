\begin{abstract}

Markov Decision Processes (MDPs) provide a powerful framework for
decision-theoretic planning.  While MDPs occur in many applications,
their applicability is limited by the common assumption that the model
parameters are known.  However, there are many settings where it is
important to solve or evaluate MDPs in the presence of uncertainty
over parameters, for example: (i) to investigate the trade-off between
different reward criteria in a multi-objective setting; (ii) to
perform sensitivity analyses of policies to various parameter
settings; and (iii) to analyse and optimise policy performance as a
function of policy parameters. However, formalizing MDPs in this way
leads to a family of hybrid (mixed discrete and continuous state and
action) MDPs with non-linear and/or piecewise structure. In this paper
we show how each of the aforementioned use cases can be formalized
under the common framework of parameterized hybrid MDPs and solved
exactly and in closed-form by leveraging techniques from symbolic
dynamic programming. Our novel framework allows one to explore for the
first-time: (i) an exact functional representation of the
multi-objective trade-offs for use in (Interactive) Decision Maps;
(ii) exact sensitivity analysis of public health policies in epidemic
models over the full range of infection rate parameters; and (iii)
non-convex optimization of policy parameters applied to finance
problems previously impossible with sample-based policy gradient
techniques.

\end{abstract}
