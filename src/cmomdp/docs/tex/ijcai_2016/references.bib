% Encoding: UTF-8

@InProceedings{Gopalan_COLT_2015,
  author =    {Aditya Gopalan and Shie Mannor},
  title =     {Thompson Sampling for Learning Parameterized Markov Decision Processes},
  booktitle = {COLT},
  year =      {2015},
  pages =     {861--898},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl =    {http://dblp.uni-trier.de/rec/bib/conf/colt/GopalanM15},
  crossref =  {DBLP:conf/colt/2015},
  timestamp = {Mon, 06 Jul 2015 08:31:46 +0200},
  url =       {http://jmlr.org/proceedings/papers/v40/Gopalan15.html}
}

@InProceedings{Pirotta_AAAI_2015,
  author =    {Matteo Pirotta and Simone Parisi and Marcello Restelli},
  title =     {Multi-Objective Reinforcement Learning with Continuous Pareto Frontier Approximation},
  booktitle = {AAAI},
  year =      {2015},
  pages =     {2928--2934},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl =    {http://dblp2.uni-trier.de/rec/bib/conf/aaai/PirottaPR15},
  crossref =  {DBLP:conf/aaai/2015},
  timestamp = {Sun, 12 Apr 2015 15:18:08 +0200},
  url =       {http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9798}
}

@Article{Bahar_JoFMiSD_1993,
  author =        {Bahar, R.I. and Frohm, E.A. and Gaona, C.M. and Hachtel, G.D. and Macii, E. and Pardo, A. and Somenzi, F.},
  title =         {Algebraic Decision Diagrams and Their Applications},
  journal =       {Journal of Formal Methods in Systems Design},
  year =          {1993},
  volume =        {10},
  pages =         {171--206},
  __markedentry = {[skinathil:6]},
  doi =           {10.1109/ICCAD.1993.580054},
  keywords =      {{ADD}, Boolean Algebra, {DAG}, Data Structure, Decision Diagram, Directed Acyclic Graph},
  url =           {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=580054},
  urldate =       {2013-09-16}
}

@InProceedings{Barrett_ICML_2008,
  author =        {Barrett, Leon and Narayanan, Srini},
  title =         {Learning All Optimal Policies with Multiple Criteria},
  booktitle =     {ICML},
  year =          {2008},
  series =        {ICML '08},
  pages =         {41--47},
  address =       {New York, NY, USA},
  publisher =     {ACM},
  acmid =         {1390162},
  bdsk-url-1 =    {http://doi.acm.org/10.1145/1390156.1390162},
  bdsk-url-2 =    {http://dx.doi.org/10.1145/1390156.1390162},
  date-added =    {2015-11-26 21:06:16 +0000},
  date-modified = {2015-11-26 21:06:28 +0000},
  doi =           {10.1145/1390156.1390162},
  isbn =          {978-1-60558-205-4},
  location =      {Helsinki, Finland},
  numpages =      {7},
  url =           {http://doi.acm.org/10.1145/1390156.1390162}
}

@Article{Barto_AI_1995,
  author =    {Barto, Andrew G. and Bradtke, Steven J. and Singh, Satinder P.},
  title =     {Learning to Act using Real-Time Dynamic Programming},
  journal =   {Artificial Intelligence},
  year =      {1995},
  volume =    {72},
  number =    {1-2},
  pages =     {81--138},
  keywords =  {{RTDP}},
  owner =     {skinathil},
  timestamp = {2014.02.05},
  url =       {http://www.sciencedirect.com/science/article/pii/000437029400011O}
}

@InProceedings{Baxter_ISCAS_2000,
  author =       {Baxter, Jonathan and Bartlett, Peter L},
  title =        {Direct gradient-based reinforcement learning},
  booktitle =    {Circuits and Systems.},
  year =         {2000},
  volume =       {3},
  pages =        {271--274},
  organization = {IEEE}
}

@book{Bellman_PU_1957,
	Address = {Princeton, NJ},
	Author = {Bellman, Richard E.},
	Date-Added = {2015-11-12 07:47:16 +0000},
	Date-Modified = {2015-11-12 07:47:36 +0000},
	Keywords = {DP, Dynamic Programming},
	Publisher = {Princeton University Press},
	Title = {Dynamic {Programming}},
	Year = {1957}}

@book{Bertsekas_1987,
	Address = {Upper Saddle River, NJ, USA},
	Author = {Bertsekas, Dimitri P.},
	Date-Added = {2016-01-26 10:52:11 +0000},
	Date-Modified = {2016-01-26 10:52:11 +0000},
	Isbn = {0132215810},
	Publisher = {Prentice-Hall, Inc.},
	Title = {Dynamic Programming: Deterministic and Stochastic Models},
	Year = {1987}}

@article{Bertsimas_JFM_1998,
	Author = {Bertsimas, Dimitris and Lo, Andrew},
	Date-Added = {2015-11-26 16:52:34 +0000},
	Date-Modified = {2015-11-26 16:55:39 +0000},
	Journal = {Journal of Financial Markets},
	Number = {1},
	Pages = {1--50},
	Title = {Optimal control of execution costs},
	Volume = {1},
	Year = {1998},
	Bdsk-Url-1 = {http://EconPapers.repec.org/RePEc:eee:finmar:v:1:y:1998:i:1:p:1-50}}

@inproceedings{Boutilier_IJCAI_2001,
	Author = {Boutilier, Craig and Reiter, Ray and Price, Bob},
	Booktitle = {IJCAI},
	Date-Added = {2015-11-26 21:49:30 +0000},
	Date-Modified = {2015-11-26 21:49:30 +0000},
	Owner = {skinathil},
	Pages = {690--697},
	Timestamp = {2014.05.29},
	Title = {{Symbolic Dynamic Programming for First-order MDPs}},
	Year = {2001}}

@Article{Boutilier_JAIR_1999,
  author =        {Boutilier, Craig and Dean, Thomas and Hanks, Steve},
  title =         {Decision-{Theoretic} {Planning}: {Structural} {Assumptions} and {Computational} {Leverage}},
  journal =       {JAIR},
  year =          {1999},
  volume =        {11},
  pages =         {1--94},
  date-added =    {2016-01-26 23:44:12 +0000},
  date-modified = {2016-01-26 23:44:28 +0000},
  keywords =      {DTP, MDP}
}

@incollection{Boyan_NIPS_2000,
	Author = {Justin A. Boyan and Michael L. Littman},
	Booktitle = {Advances in Neural Information Processing Systems 13},
	Date-Added = {2015-11-24 05:03:29 +0000},
	Date-Modified = {2015-11-24 05:04:07 +0000},
	Editor = {T.K. Leen and T.G. Dietterich and V. Tresp},
	Pages = {1026--1032},
	Publisher = {MIT Press},
	Title = {Exact Solutions to Time-Dependent MDPs},
	Url = {http://papers.nips.cc/paper/1811-exact-solutions-to-time-dependent-mdps.pdf},
	Year = {2001},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/1811-exact-solutions-to-time-dependent-mdps.pdf}}

@techreport{Chan_MIT_2001,
	Author = {Nicholas T. Chan and Christian R. Shelton},
	Date-Added = {2015-11-12 08:14:03 +0000},
	Date-Modified = {2015-11-12 08:14:15 +0000},
	Institution = {{MIT} {AI} Lab},
	Month = Apr,
	Number = {2001-005},
	Title = {An Electronic Market-Maker},
	Type = {AI Memo},
	Year = 2001}

@InCollection{Chatterjee_STACS_2006,
  author =    {Chatterjee, Krishnendu and Majumdar, Rupak and Henzinger, Thomas A},
  title =     {Markov decision processes with multiple objectives},
  booktitle = {STACS 2006},
  publisher = {Springer},
  year =      {2006},
  pages =     {325--336}
}

@InProceedings{Dearden_UAI_1999,
  author =        {Dearden, Richard and Friedman, Nir and Andre, David},
  title =         {Model Based Bayesian Exploration},
  booktitle =     {UAI},
  year =          {1999},
  series =        {UAI'99},
  pages =         {150--159},
  address =       {San Francisco, CA, USA},
  publisher =     {Morgan Kaufmann Publishers Inc.},
  acmid =         {2073814},
  bdsk-url-1 =    {http://dl.acm.org/citation.cfm?id=2073796.2073814},
  date-added =    {2016-01-26 10:54:08 +0000},
  date-modified = {2016-01-26 10:54:20 +0000},
  isbn =          {1-55860-614-9},
  location =      {Stockholm, Sweden},
  numpages =      {10},
  url =           {http://dl.acm.org/citation.cfm?id=2073796.2073814}
}

@PhdThesis{Duff_UMA_2002,
  author = {Duff, Michael O'Gordon},
  title =  {Optimal Learning: Computational procedures for Bayes-adaptive Markov decision processes},
  school = {University of Massachusetts Amherst},
  year =   {2002}
}

@Article{Givan_AI_2000,
  author =   {Robert Givan and Sonia Leach and Thomas Dean},
  title =    {Bounded-parameter Markov decision processes},
  journal =  {Artificial Intelligence },
  year =     {2000},
  volume =   {122},
  number =   {1â€“2},
  pages =    {71--109},
  doi =      {http://dx.doi.org/10.1016/S0004-3702(00)00047-3},
  issn =     {0004-3702},
  keywords = {Decision-theoretic planning},
  url =      {http://www.sciencedirect.com/science/article/pii/S0004370200000473}
}

@Article{Hopp_JOTA_1988,
  author =  {Hopp, W. J.},
  title =   {Sensitivity analysis in discrete dynamic programming},
  journal = {Journal of Optimization Theory and Applications},
  year =    {1988},
  volume =  {56},
  number =  {2},
  pages =   {257--269},
  doi =     {10.1007/BF00939411},
  issn =    {1573-2878},
  url =     {http://dx.doi.org/10.1007/BF00939411}
}

@book{Howard_MIT_1960,
	Address = {Cambridge, Massachusetts, USA},
	Author = {Howard, Ronald Arthur},
	Date-Added = {2015-11-12 07:44:54 +0000},
	Date-Modified = {2015-11-12 07:48:18 +0000},
	Isbn = {0-262-08009-5 978-0-262-08009-5},
	Keywords = {DP, Dynamic Programming, MDP, Policy Iteration},
	Publisher = {The MIT press},
	Title = {Dynamic {Programming} and {Markov} {Processes}},
	Year = {1960}}

@article{Kaelbling_JoAIR_1998,
	Author = {Kaelbling, Leslie Pack and Littman, Michael L. and Cassandra, Anthony R.},
	Date-Added = {2015-11-10 11:33:12 +0000},
	Date-Modified = {2015-11-10 11:33:12 +0000},
	Doi = {http://dx.doi.org/10.1016/S0004-3702(98)00023-X},
	Issn = {0004-3702},
	Journal = {JAIR},
	Keywords = {{MDP}, {POMDP}},
	Owner = {skinathil},
	Pages = {99--134},
	Timestamp = {2014.05.23},
	Title = {{Planning and Acting in Partially Observable Stochastic Domains}},
	Url = {http://www.sciencedirect.com/science/article/pii/S000437029800023X},
	Volume = {101},
	Year = {1998},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S000437029800023X},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/S0004-3702(98)00023-X}}

@Article{Kalyanasundaram_AJC_2004,
  author =    {Kalyanasundaram, Suresh and Chong, Edwin K. P. and Shroff, Ness B.},
  title =     {Markov decision processes with uncertain transition rates: sensitivity and max hyphen min control},
  journal =   {Asian Journal of Control},
  year =      {2004},
  volume =    {6},
  number =    {2},
  pages =     {253--269},
  doi =       {10.1111/j.1934-6093.2004.tb00203.x},
  issn =      {1934-6093},
  keywords =  {Markov decision processes, sensitivity, max-min control, call admission control, policy iteration},
  publisher = {Blackwell Publishing Ltd},
  url =       {http://dx.doi.org/10.1111/j.1934-6093.2004.tb00203.x}
}

@InProceedings{Li_AAAI_2005,
  author =    {Li, Lihong and Littman, Michael L.},
  title =     {Lazy Approximation for Solving Continuous Finite-horizon MDPs},
  booktitle = {AAAI},
  year =      {2005},
  volume =    {3},
  series =    {AAAI},
  pages =     {1175--1180},
  publisher = {AAAI Press},
  acmid =     {1619522},
  isbn =      {1-57735-236-x},
  location =  {Pittsburgh, Pennsylvania},
  numpages =  {6},
  url =       {http://dl.acm.org/citation.cfm?id=1619499.1619522}
}

@Book{Lotov_IDM,
  title =     {Interactive Decision Maps: Approximation and Visualization of Pareto Frontier},
  publisher = {Springer US},
  year =      {2004},
  author =    {Lotov, A. V. and Bushenkov, V. A. and Kamenev, G. K},
  volume =    {89},
  edition =   {1}
}

@Article{Meuleau_JoAIR_2009,
  author =    {Nicolas Meuleau and Emmanuel Benazera and Ronen I. Brafman and Eric A. Hansen and Mausam},
  title =     {A Heuristic Search Approach to Planning with Continuous Resources in Stochastic Domains},
  journal =   {JAIR},
  year =      {2009},
  volume =    {34},
  pages =     {27--59},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee =        {http://dx.doi.org/10.1613/jair.2529}
}

@InProceedings{Ng_UAI_2000,
  author =    {A. Y. Ng and M. Jordan},
  title =     {PEGASUS: A policy search method for large MPDs and POMDPs},
  booktitle = {UAI},
  year =      {2000}
}

@Conference{Perny_AAAI_2013,
  author =    {Perny, Patrice and Weng, Paul and Goldsmith, Judy and Hanna, Josiah P},
  title =     {Approximation of Lorenz-Optimal Solutions in Multiobjective Markov Decision Processes},
  booktitle = {Workshops at the Twenty Seventh AAAI Conference on Artificial Intelligence},
  year =      {2013},
  journal =   {Workshops at the TwentySeventh AAAI Conference on Artificial Intelligence}
}

@Article{Perold_JPM_1988,
  author =        {Andr{\'e} F. Perold},
  title =         {The implementation shortfall: Paper versus reality},
  journal =       {The Journal of Portfolio Management},
  year =          {1988},
  volume =        {14},
  number =        {3},
  pages =         {4--9},
  date-added =    {2015-04-15 07:50:15 +0000},
  date-modified = {2015-04-15 07:52:46 +0000}
}

@InProceedings{Peters_IRS_2006,
  author =       {Peters, Jan and Schaal, Stefan},
  title =        {Policy gradient methods for robotics},
  booktitle =    {Intelligent Robots and Systems},
  year =         {2006},
  pages =        {2219--2225},
  organization = {IEEE}
}

@inproceedings{Pineau_IJCAI_2003,
	Author = {Pineau, Joelle and Gordon, Geoffrey J. and Thrun, Sebastian},
	Booktitle = {IJCAI},
	Date-Added = {2015-11-10 12:03:08 +0000},
	Date-Modified = {2015-11-10 12:03:08 +0000},
	File = {Pineau_IJCAI_2003-PointBasedValueIterationAnytimeAlgorithmPOMDPs.pdf:C\:\\Users\\skinathil\\phd\\references\\Pineau_IJCAI_2003-PointBasedValueIterationAnytimeAlgorithmPOMDPs.pdf:application/pdf},
	Keywords = {Algorithm, {POMDP}},
	Pages = {1025--1030},
	Title = {{Point-based Value Iteration: An Anytime Algorithm for {POMDPs}}},
	Url = {http://dl.acm.org/citation.cfm?id=1630659.1630806},
	Year = {2003},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1630659.1630806}}

@InProceedings{Reddy_IJCAI_2011,
  author =    {Reddy, Prashant P and Veloso, Manuela M},
  title =     {Strategy learning for autonomous agents in smart grid markets},
  booktitle = {IJCAI},
  year =      {2011},
  volume =    {22},
  number =    {1},
  pages =     {1446}
}

@Article{Roijers_JAIR_2013,
  author =        {Roijers, Diederik M. and Vamplew, Peter and Whiteson, Shimon and {Richard Dazeley}},
  title =         {A {Survey} of {Multi}-{Objective} {Sequential} {Decision}-{Making}},
  journal =       {JAIR},
  year =          {2013},
  volume =        {48},
  pages =         {67--113},
  __markedentry = {[skin:6]}
}

@inproceedings{Sanner_UAI_2011,
	Author = {Sanner, Scott and Delgado, Karina and Nunes de Barros, Leliane},
	Booktitle = {UAI},
	Date-Added = {2016-01-19 04:48:21 +0000},
	Date-Modified = {2016-01-19 04:49:57 +0000},
	Pages = {1--10},
	Title = {{Symbolic Dynamic Programming for Discrete and Continuous State MDPs}},
	Year = {2011}}

@Article{sherali1992global,
  author =    {Sherali, Hanif D and Tuncbilek, Cihan H},
  title =     {A global optimization algorithm for polynomial programming problems using a reformulation-linearization technique},
  journal =   {Journal of Global Optimization},
  year =      {1992},
  volume =    {2},
  number =    {1},
  pages =     {101--112},
  publisher = {Springer}
}

@InProceedings{St-Aubin_NIPS_2000,
  author =    {St-Aubin, Robert and Hoey, Jesse and Boutilier, Craig},
  title =     {{APRICODD:} Approximate Policy Construction Using Decision Diagrams},
  booktitle = {NIPS},
  year =      {2000},
  series =    {{NIPS}},
  pages =     {1089 -- 1095},
  address =   {Denver, Colorado, {USA}},
  publisher = {{MIT} Press},
  keywords =  {{ADD}, Algorithm, {MDP}},
  owner =     {skinathil},
  timestamp = {2014.06.16},
  url =       {http://dblp.uni-trier.de/db/conf/nips/nips2000.html#St-AubinHB00}
}

@InCollection{Sutton_NIPS_1999,
  author =    {Sutton, Richard S and David A. McAllester and Satinder P. Singh and Mansour, Yishay},
  title =     {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  booktitle = {Advances in Neural Information Processing Systems 12},
  publisher = {MIT Press},
  year =      {2000},
  editor =    {S.A. Solla and T.K. Leen and K. M\"{u}ller},
  pages =     {1057--1063},
  url =       {http://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf}
}

@InCollection{Szita_RL_2012,
  author =    {Szita, Istv{\'a}n},
  title =     {Reinforcement learning in games},
  booktitle = {Reinforcement Learning},
  publisher = {Springer Berlin Heidelberg},
  year =      {2012},
  pages =     {539--577}
}

@Article{Tan_JAP_2011,
  author =    {Tan, Chin Hon and Hartman, Joseph C.},
  title =     {Sensitivity analysis in Markov decision processes with uncertain reward parameters},
  journal =   {Journal of Applied Probability},
  year =      {2011},
  volume =    {48},
  number =    {4},
  pages =     {954--967},
  month =     {12},
  doi =       {10.1239/jap/1324046012},
  fjournal =  {Journal of Applied Probability},
  publisher = {Applied Probability Trust},
  url =       {http://dx.doi.org/10.1239/jap/1324046012}
}

@InProceedings{Vianna_UAI_2013,
  author =    {Vianna, Luis Gustavo Rocha and Sanner, Scott and Nunes de Barros, Leliane},
  title =     {Bounded Approximate Symbolic Dynamic Programming for Hybrid {MDPs}},
  booktitle = {UAI},
  year =      {2013},
  series =    {{UAI}},
  pages =     {1--9},
  address =   {Bellevue, {USA}},
  keywords =  {{MDP}, {SDP}, {XADD}},
  owner =     {skinathil},
  timestamp = {2014.03.15},
  url =       {auai.org/uai2013/prints/papers/125.pdf}
}

@article{Viswanathan_TIMS_1977,
	Author = {Viswanathan, B. and Aggarwal, V.V. and Nair, K.P.K.},
	Date-Added = {2015-11-10 10:37:18 +0000},
	Date-Modified = {2015-11-10 10:42:32 +0000},
	Journal = {TIMS Studies in the Management Sciences},
	Pages = {263--272},
	Title = {Multiple criteria Markov decision processes},
	Volume = {6},
	Year = {1977}}

@article{White_LSS_1980,
	Author = {White III, C. C. and Kim, K. M.},
	Date-Added = {2015-11-10 10:47:00 +0000},
	Date-Modified = {2015-11-24 04:51:48 +0000},
	Journal = {Large Scale Systems},
	Pages = {129--140},
	Title = {Solution Procedures for Solving Vector Criterion {Markov} Decision Processes},
	Volume = {1},
	Year = {1980}}

@Article{Williams_EM_2009,
  author =   {Byron K. Williams},
  title =    {Markov decision processes in natural resources management: Observability and uncertainty },
  journal =  {Ecological Modelling },
  year =     {2009},
  volume =   {220},
  number =   {6},
  pages =    {830--840},
  doi =      {http://dx.doi.org/10.1016/j.ecolmodel.2008.12.023},
  issn =     {0304-3800},
  keywords = {Natural resources},
  url =      {http://www.sciencedirect.com/science/article/pii/S0304380009000246}
}

@inproceedings{Zamani_AAAI_2012,
	Author = {Zamani, Zahra and Sanner, Scott},
	Booktitle = {AAAI},
	Date-Added = {2016-01-19 04:50:04 +0000},
	Date-Modified = {2016-01-19 04:50:56 +0000},
	Pages = {1--7},
	Title = {Symbolic Dynamic Programming for Continuous State and Action MDPs},
	Year = {2012}}

@Article{Zhu_AIM_2014,
  author =        {George Zhu and Dan Lizotte and Jesse Hoey},
  title =         {Scalable approximate policies for Markov decision process models of hospital elective admissions },
  journal =       {Artificial Intelligence in Medicine },
  year =          {2014},
  volume =        {61},
  number =        {1},
  pages =         {21--34},
  __markedentry = {[skin:]},
  doi =           {http://dx.doi.org/10.1016/j.artmed.2014.04.001},
  issn =          {0933-3657},
  keywords =      {Markov decision process},
  url =           {http://www.sciencedirect.com/science/article/pii/S0933365714000372}
}
